{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "191c8c14306e497d",
   "metadata": {},
   "source": [
    "# **Financial Article Classification Using Machine Learning**\n",
    "#### *by: Abba Ali-Concern*\n",
    "\n",
    "---\n",
    "### Introduction\n",
    "\n",
    "Financial information is generated in huge volumes daily, making automatic classification essential for efficient content management. This project aims to build a machine learning model to categorize financial articles using natural language processing (NLP) techniques.\n",
    "\n",
    "The notebook will cover data sourcing, preprocessing, and a comparison of classification models to determine the most accurate one for this task. We will also address challenges like finding relevant labeled data and feature extraction for improved model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5ba0b0ba895a35d0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-07T00:23:33.342883Z",
     "start_time": "2024-10-07T00:23:21.596408Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined dataset saved as 'twitter_financial_news_combined.csv'.\n"
     ]
    }
   ],
   "source": [
    "# Import packages\n",
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "\n",
    "# Load the dataset from Hugging Face\n",
    "dataset = load_dataset('zeroshot/twitter-financial-news-topic')\n",
    "\n",
    "# Convert the 'train' and 'validation' splits into DataFrames\n",
    "train_df = pd.DataFrame(dataset['train'])\n",
    "test_df = pd.DataFrame(dataset['validation'])\n",
    "\n",
    "# Combine the train and test datasets\n",
    "combined_df = pd.concat([train_df, test_df], ignore_index=True)\n",
    "\n",
    "# Save the combined dataset as a CSV file\n",
    "combined_df.to_csv('twitter_financial_news_combined.csv', index=False)\n",
    "\n",
    "print(\"Combined dataset saved as 'twitter_financial_news_combined.csv'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "178a016a",
   "metadata": {},
   "source": [
    "\n",
    "### Dataset Selection Challenges  \n",
    "Finding a dataset with specific labels for financial topics was challenging. To improve model performance for this use case, I downloaded a general financial article dataset. Then, I extracted keywords from each article title to create more relevant labels.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f0423bedf0996977",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-07T00:27:40.817399Z",
     "start_time": "2024-10-07T00:27:38.987169Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text       category\n",
      "0  Here are Thursday's biggest analyst calls: App...  Uncategorized\n",
      "1  Buy Las Vegas Sands as travel to Singapore bui...         Stocks\n",
      "2  Piper Sandler downgrades DocuSign to sell, cit...         Stocks\n",
      "3  Analysts react to Tesla's latest earnings, bre...         Stocks\n",
      "4  Netflix and its peers are set for a ‘return to...         Stocks\n"
     ]
    }
   ],
   "source": [
    "# Import Packages\n",
    "import re\n",
    "\n",
    "# Load your dataset\n",
    "df = pd.read_csv('twitter_financial_news_combined.csv')\n",
    "\n",
    "# Define keywords for each category\n",
    "keywords = {\n",
    "    'Cryptocurrency': ['bitcoin', 'ethereum', 'crypto', 'blockchain', 'altcoin', 'token'],\n",
    "    'Stocks': ['stock', 'equity', 'shares', 'buy', 'sell', 'earnings', 'ipo'],\n",
    "    'Economy': ['inflation', 'gdp', 'recession', 'unemployment', 'economy', 'growth'],\n",
    "    'Banking': ['bank', 'interest rates', 'mortgage', 'lending', 'finance'],\n",
    "    'Investments': ['portfolio', 'hedge fund', 'mutual fund', 'etf', 'bonds', 'assets']\n",
    "}\n",
    "\n",
    "# Function to clean and categorize text\n",
    "def categorize_text(text):\n",
    "    # Lowercase and remove special characters\n",
    "    text = re.sub(r'http\\S+|[^a-zA-Z\\s]', '', text.lower())\n",
    "    \n",
    "    # Check for keywords in the text\n",
    "    for category, words in keywords.items():\n",
    "        if any(word in text for word in words):\n",
    "            return category\n",
    "    return 'Uncategorized'  # For texts that don't match any category\n",
    "\n",
    "# Apply categorization\n",
    "df['category'] = df['text'].apply(categorize_text)\n",
    "\n",
    "# Display first few rows to check results\n",
    "print(df[['text', 'category']].head())\n",
    "\n",
    "# Save to a new CSV\n",
    "df.to_csv('categorized_dataset.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "18e648258f5d9f29",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-07T00:31:00.907988Z",
     "start_time": "2024-10-07T00:31:00.889920Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Here are Thursday's biggest analyst calls: App...</td>\n",
       "      <td>Uncategorized</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Buy Las Vegas Sands as travel to Singapore bui...</td>\n",
       "      <td>Stocks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Piper Sandler downgrades DocuSign to sell, cit...</td>\n",
       "      <td>Stocks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Analysts react to Tesla's latest earnings, bre...</td>\n",
       "      <td>Stocks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Netflix and its peers are set for a ‘return to...</td>\n",
       "      <td>Stocks</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text       category\n",
       "0  Here are Thursday's biggest analyst calls: App...  Uncategorized\n",
       "1  Buy Las Vegas Sands as travel to Singapore bui...         Stocks\n",
       "2  Piper Sandler downgrades DocuSign to sell, cit...         Stocks\n",
       "3  Analysts react to Tesla's latest earnings, bre...         Stocks\n",
       "4  Netflix and its peers are set for a ‘return to...         Stocks"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Assign new dataframe\n",
    "organized_df = df[['text', 'category']]\n",
    "organized_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8d60ff05b3b2d499",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-07T00:34:22.243139Z",
     "start_time": "2024-10-07T00:34:22.228984Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text        0\n",
       "category    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for missing values\n",
    "organized_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ba5824f4f031fb5d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-07T00:34:24.217020Z",
     "start_time": "2024-10-07T00:34:24.200749Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "category\n",
       "Uncategorized     13392\n",
       "Stocks             4182\n",
       "Economy            1800\n",
       "Banking             968\n",
       "Cryptocurrency      402\n",
       "Investments         363\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View target values\n",
    "organized_df[\"category\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "3876c80dfce49147",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-07T00:42:21.464061Z",
     "start_time": "2024-10-07T00:42:19.751648Z"
    }
   },
   "outputs": [],
   "source": [
    "# Import necessary packages\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# CountVectorizer to convert text into a matrix of token counts\n",
    "vectorizer = CountVectorizer(stop_words='english')\n",
    "X = vectorizer.fit_transform(organized_df['text'])  # Convert text into numeric features\n",
    "\n",
    "# Train-Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, organized_df['category'], test_size=0.2, random_state=42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "58f3d7a7538391fd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-07T00:43:48.610200Z",
     "start_time": "2024-10-07T00:43:39.556184Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.980104216011369\n",
      "Classification Report:\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "       Banking       0.98      0.90      0.94       199\n",
      "Cryptocurrency       1.00      0.85      0.92        89\n",
      "       Economy       0.98      0.99      0.98       382\n",
      "   Investments       0.97      0.92      0.94        74\n",
      "        Stocks       0.99      0.95      0.97       816\n",
      " Uncategorized       0.98      1.00      0.99      2662\n",
      "\n",
      "      accuracy                           0.98      4222\n",
      "     macro avg       0.98      0.94      0.96      4222\n",
      "  weighted avg       0.98      0.98      0.98      4222\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import necessary packages\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Model 1: Logistic Regression\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "\n",
    "# Model 2: Naive Bayes\n",
    "# model = MultinomialNB()\n",
    "\n",
    "# Fit the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Step 4: Make Predictions and Evaluate the Model\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Step 5: Evaluate the Model\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred)}\")\n",
    "print(f\"Classification Report:\\n{classification_report(y_test, y_pred)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe7e16b888504bea",
   "metadata": {},
   "source": [
    "### Model Comparison Results  \n",
    "- Naive Bayes achieved an accuracy of 84%. \n",
    "- Logistic Regression achieved an accuracy of 98%.\n",
    "\n",
    "Based on these results, we will proceed with the Logistic Regression model.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d1e8f2e9e4246e13",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-07T00:53:49.750990Z",
     "start_time": "2024-10-07T00:53:49.331123Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved as text_classification_model.joblib\n",
      "Vectorizer saved as vectorizer.joblib\n"
     ]
    }
   ],
   "source": [
    "# Import packages\n",
    "import joblib\n",
    "\n",
    "# Save the model \n",
    "model_filename = 'text_classification_model.joblib'\n",
    "joblib.dump(model, model_filename)\n",
    "print(f\"Model saved as {model_filename}\")\n",
    "\n",
    "# Save the vectorizer\n",
    "vectorizer_filename = 'vectorizer.joblib'\n",
    "joblib.dump(vectorizer, vectorizer_filename)\n",
    "print(f\"Vectorizer saved as {vectorizer_filename}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
